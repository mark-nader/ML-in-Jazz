=================== NOT NORMALISED ===================

	training on single song, 1000 epochs
		
		standard hyperparameters
		network structure [6,8,8,12] 			-- error 1.01
		
		standard hyperparameters
		network structure [6,12,12,12] 			-- error 0.70
		
		standard hyperparameters
		network structure [6,12,12,12,12]	 	-- error 0.53
		
		standard hyperparameters
		network structure [6,12,12,12,12,12] 	-- error 0.48
		
		change learning rate to 0.005
		network structure [6,12,12,12,12,12]	-- error 0.94
		
		change momentum gamma to 0.65
		network structure [6,12,12,12,12,12]	-- error 0.46
		
	training on 5 songs, 1000 epochs
	
		change momentum gamma to 0.65
		network structure [6,12,12,12,12,12]	-- error 1.78
		
	training on 100 songs, 1000 epochs
	
		change momentum gamma to 0.65
		network structure [6,12,12,12,12,12]	-- error 2.13

	training on 100 songs, 1000 epochs
	
		change learning rate to 0.005
		change momentum gamma to 0.6
		network structure [6,12,12,12,12,12]	-- error 2.18

NEW NETWORK STRUCTURE: [72,12,12,12,12,12]
inputs are note intervals mod 12 represented as 6 sets of 12 numbers
each 12 numbers has eleven 0s and one 1, the index of the 1 denotes
the interval

	training on single song, 1000 epochs
		
		standard hyperparameters
		network structure [72,12,12,12,12,12] 	-- error 0.25

		change learning rate to 0.005
		network structure [72,12,12,12,12,12] 	-- error 0.31
		
	training on 10 songs, 1000 epochs
	
		change momentum gamma to 0.65
		network structure [72,12,12,12,12,12] 	-- error 1.44
		
		change momentum gamma to 0.35
		network structure [72,12,12,12,12,12] 	-- error 1.28
		
		change momentum gamma to 0.35
		network structure [72,36,24,24,24,12] 	-- error 0.18
		
		change momentum gamma to 0.35
		network structure [72,72,36,24,24,12] 	-- error 0.26
		
	training on 100 songs, 1000 epochs
		
		change momentum gamma to 0.35
		network structure [72,72,36,24,24,12] 	-- error 1.34, 1.49
		
		change momentum gamma to 0.35
		network structure [72,72,72,36,24,12] 	-- error 1.42, 1.44
		
		change momentum gamma to 0.3
		change learning rate to 0.005
		network structure [72,72,72,36,24,12] 	-- error 1.69
		
		change momentum gamma to 0.4
		change learning rate to 0.0005
		network structure [72,72,36,36,24,12] 	-- error 1.42
		
		change momentum gamma to 0.4
		network structure [72,72,36,24,12,12] 	-- error 1.51
		
		change momentum gamma to 0.35
		change l2 Lambda to 0.005
		network structure [72,36,24,24,24,12] 	-- error 1.92
		
		change momentum gamma to 0.35
		change l2 Lambda to 0.005
		change learning rate to 0.0005
		network structure [72,72,24,24,24,12] 	-- error 2.07
		
		change momentum gamma to 0.3
		change learning rate to 0.0005
		network structure [72,72,72,36,24,12] 	-- error 1.23, 1.36, 1.25
		
		change momentum gamma to 0.2
		change learning rate to 0.0005
		network structure [72,72,72,36,24,12] 	-- error 1.17, 1.45, 1.33
		
		change momentum gamma to 0.1
		change learning rate to 0.0005
		network structure [72,72,72,36,24,12] 	-- error 1.35, 1.29
		
		change momentum gamma to 0.2
		network structure [72,72,72,36,24,12] 	-- error 1.46
		
	training on 10 songs, 1000 epochs
		
		change momentum gamma to 0.3
		change learning rate to 0.0005
		network structure [72,72,72,36,24,12] 	-- error 0.31
		
		change momentum gamma to 0.2
		change learning rate to 0.0005
		network structure [72,72,72,36,24,12] 	-- error 0.29
		
		change momentum gamma to 0.1
		change learning rate to 0.0005
		network structure [72,72,72,36,24,12] 	-- error 0.27
		
		change useMomentum to False
		change learning rate to 0.0005
		network structure [72,72,72,36,24,12] 	-- error 0.29
		
NEW NETWORK STRUCTURE ADDING 3 EXTRA NOTES FOR A TOTAL OF 9
input size now 108

	training on 100 songs, 100 epochs
	
		useMomentum=False
		network structure [108,108,108,54,27,12]	-- error 1.17
		
NEW NETWORK STRUCTURE ADDING 2 EXTRA NOTES FOR A TOTAL OF 8
input size now 96

	training on 100 songs, 100 epochs
	
		useMomentum=False
		network structure [96,96,96,48,24,12]	-- error 1.14
		
		useMomentum=True
		momentumGamma=0.1
		learningRate=0.0005
		network structure [96,96,96,48,24,12]	-- error 1.23
		
	training on 1000 songs, 100 epochs
		
		useMomentum=False
		network structure [96,96,96,48,24,12]	-- error 1.71
		
	these proved no better in BassNoteNetsCategorise so i will use the 6 note input network
	
NEW NETWORK MODEL
USING RNN/LSTM

	batchSize, dimIn, dimHidden, dimOut, hiddenLayers = 1, 12, 128, 12, 2
	trainSize, testSize = 800, 200
	learningRate, weightDecay = 0.01, 0.001
	numEpochs=50
	testEvery=10
	Adamax
		training set loss: 2.0466115474700928 -- epoch 10/50
		testing set loss: 2.048365592956543 -- epoch 10/50 [|TEST DATA|]
		training set loss: 1.9269239902496338 -- epoch 20/50
		testing set loss: 1.9987833499908447 -- epoch 20/50 [|TEST DATA|]
		training set loss: 1.8574923276901245 -- epoch 30/50
		testing set loss: 1.9484519958496094 -- epoch 30/50 [|TEST DATA|]
		training set loss: 1.821153163909912 -- epoch 40/50
		testing set loss: 1.9336471557617188 -- epoch 40/50 [|TEST DATA|]
		training set loss: 1.8018072843551636 -- epoch 50/50
		testing set loss: 1.9249690771102905 -- epoch 50/50 [|TEST DATA|]
		
	batchSize, dimIn, dimHidden, dimOut, hiddenLayers = 1, 12, 128, 12, 2
	trainSize, testSize = 800, 200
	learningRate, weightDecay = 0.01, 0.001
	numEpochs=100
	testEvery=10
	Adamax
		training set loss: 2.0952155590057373 -- epoch 5/100
		testing set loss: 2.180678367614746 -- epoch 5/100 [|TEST DATA|]
		training set loss: 2.0505173206329346 -- epoch 10/100
		testing set loss: 2.1175625324249268 -- epoch 10/100 [|TEST DATA|]
		training set loss: 2.038604974746704 -- epoch 15/100
		testing set loss: 2.1032450199127197 -- epoch 15/100 [|TEST DATA|]
		training set loss: 2.0233492851257324 -- epoch 20/100
		testing set loss: 2.0785133838653564 -- epoch 20/100 [|TEST DATA|]
		training set loss: 1.9891637563705444 -- epoch 25/100
		testing set loss: 2.0234317779541016 -- epoch 25/100 [|TEST DATA|]
		training set loss: 1.9681365489959717 -- epoch 30/100
		testing set loss: 2.004693031311035 -- epoch 30/100 [|TEST DATA|]
		training set loss: 1.9519050121307373 -- epoch 35/100
		testing set loss: 1.9859728813171387 -- epoch 35/100 [|TEST DATA|]
		training set loss: 1.931434988975525 -- epoch 40/100
		testing set loss: 1.960845947265625 -- epoch 40/100 [|TEST DATA|]
		training set loss: 1.9172959327697754 -- epoch 45/100
		testing set loss: 1.9370160102844238 -- epoch 45/100 [|TEST DATA|]
		training set loss: 1.9055432081222534 -- epoch 50/100
		testing set loss: 1.922635793685913 -- epoch 50/100 [|TEST DATA|]
		training set loss: 1.8938347101211548 -- epoch 55/100
		testing set loss: 1.9084842205047607 -- epoch 55/100 [|TEST DATA|]
		training set loss: 1.8791606426239014 -- epoch 60/100
		testing set loss: 1.8991153240203857 -- epoch 60/100 [|TEST DATA|]
		training set loss: 1.8718980550765991 -- epoch 65/100
		testing set loss: 1.8931350708007812 -- epoch 65/100 [|TEST DATA|]
		training set loss: 1.8641659021377563 -- epoch 70/100
		testing set loss: 1.8851499557495117 -- epoch 70/100 [|TEST DATA|]
		training set loss: 1.8581088781356812 -- epoch 75/100
		testing set loss: 1.8740812540054321 -- epoch 75/100 [|TEST DATA|]
		training set loss: 1.8500944375991821 -- epoch 80/100
		testing set loss: 1.8714498281478882 -- epoch 80/100 [|TEST DATA|]
		training set loss: 1.8437912464141846 -- epoch 85/100
		testing set loss: 1.8610854148864746 -- epoch 85/100 [|TEST DATA|]
		training set loss: 1.840063452720642 -- epoch 90/100
		testing set loss: 1.8564053773880005 -- epoch 90/100 [|TEST DATA|]
		training set loss: 1.8353298902511597 -- epoch 95/100
		testing set loss: 1.8476060628890991 -- epoch 95/100 [|TEST DATA|]
		training set loss: 1.8288111686706543 -- epoch 100/100
		testing set loss: 1.8437261581420898 -- epoch 100/100 [|TEST DATA|]
		
	batchSize, dimIn, dimHidden, dimOut, hiddenLayers = 1, 12, 128, 12, 2
	trainSize, testSize = 800, 200
	learningRate, weightDecay = 0.01, 0.001
	numEpochs=1000
	testEvery=10
	Adamax	
		training set loss: 1.6977128982543945 -- epoch 100/1000
		testing set loss: 1.8738603591918945 -- epoch 100/1000 [|TEST DATA|]
		training set loss: 1.6391292810440063 -- epoch 200/1000
		testing set loss: 1.855830430984497 -- epoch 200/1000 [|TEST DATA|]
		training set loss: 1.6197785139083862 -- epoch 300/1000
		testing set loss: 1.8556090593338013 -- epoch 300/1000 [|TEST DATA|]
		training set loss: 1.6057066917419434 -- epoch 400/1000
		testing set loss: 1.850815773010254 -- epoch 400/1000 [|TEST DATA|]
		training set loss: 1.5970895290374756 -- epoch 500/1000
		testing set loss: 1.8491421937942505 -- epoch 500/1000 [|TEST DATA|]
		training set loss: 1.5906734466552734 -- epoch 600/1000
		testing set loss: 1.8491610288619995 -- epoch 600/1000 [|TEST DATA|]
		training set loss: 1.5810573101043701 -- epoch 700/1000
		testing set loss: 1.8467880487442017 -- epoch 700/1000 [|TEST DATA|]
		training set loss: 1.5850911140441895 -- epoch 800/1000
		testing set loss: 1.8544856309890747 -- epoch 800/1000 [|TEST DATA|]
		training set loss: 1.5868942737579346 -- epoch 900/1000
		testing set loss: 1.8590950965881348 -- epoch 900/1000 [|TEST DATA|]
		training set loss: 1.5823261737823486 -- epoch 1000/1000
		testing set loss: 1.867995023727417 -- epoch 1000/1000 [|TEST DATA|]

	batchSize, dimIn, dimHidden, dimOut, hiddenLayers = 1, 12, 128, 12, 4
	trainSize, testSize = 800, 200
	learningRate, weightDecay = 0.01, 0.001
	numEpochs=1000
	testEvery=50
	SGD
		training set loss: 2.2107207775115967 -- epoch 100/1000
		testing set loss: 2.2106754779815674 -- epoch 100/1000 [|TEST DATA|]
		training set loss: 2.210542678833008 -- epoch 200/1000
		testing set loss: 2.210592269897461 -- epoch 200/1000 [|TEST DATA|]
		training set loss: 2.2104954719543457 -- epoch 300/1000
		testing set loss: 2.2105712890625 -- epoch 300/1000 [|TEST DATA|]
		training set loss: 2.210477590560913 -- epoch 400/1000
		testing set loss: 2.2105600833892822 -- epoch 400/1000 [|TEST DATA|]
		training set loss: 2.210470676422119 -- epoch 500/1000
		testing set loss: 2.2105531692504883 -- epoch 500/1000 [|TEST DATA|]
		training set loss: 2.210468053817749 -- epoch 600/1000
		testing set loss: 2.2105488777160645 -- epoch 600/1000 [|TEST DATA|]
		training set loss: 2.21046781539917 -- epoch 700/1000
		testing set loss: 2.210545778274536 -- epoch 700/1000 [|TEST DATA|]
		training set loss: 2.210468292236328 -- epoch 800/1000
		testing set loss: 2.2105438709259033 -- epoch 800/1000 [|TEST DATA|]
		training set loss: 2.210468053817749 -- epoch 900/1000
		testing set loss: 2.210543632507324 -- epoch 900/1000 [|TEST DATA|]
		training set loss: 2.210468053817749 -- epoch 1000/1000
		testing set loss: 2.2105441093444824 -- epoch 1000/1000 [|TEST DATA|]
		
	batchSize, dimIn, dimHidden, dimOut, hiddenLayers = 1, 12, 108, 12, 4
	trainSize, testSize = 800, 200
	learningRate, weightDecay = 0.01, 0.001
	numEpochs=1000
	testEvery=50
	Adam
		training set loss: 2.2278780937194824 -- epoch 100/1000
		testing set loss: 2.231428384780884 -- epoch 100/1000 [|TEST DATA|]
		training set loss: 2.2797389030456543 -- epoch 200/1000
		testing set loss: 2.3335671424865723 -- epoch 200/1000 [|TEST DATA|]
		training set loss: 2.2341127395629883 -- epoch 300/1000
		testing set loss: 2.232480525970459 -- epoch 300/1000 [|TEST DATA|]
		training set loss: nan -- epoch 400/1000
		testing set loss: nan -- epoch 400/1000 [|TEST DATA|
		training set loss: nan -- epoch 500/1000
		testing set loss: nan -- epoch 500/1000 [|TEST DATA|]
		training set loss: nan -- epoch 600/1000
		testing set loss: nan -- epoch 600/1000 [|TEST DATA|]
		training set loss: nan -- epoch 700/1000
		testing set loss: nan -- epoch 700/1000 [|TEST DATA|]
		training set loss: nan -- epoch 800/1000
		testing set loss: nan -- epoch 800/1000 [|TEST DATA|]
		training set loss: nan -- epoch 900/1000
		testing set loss: nan -- epoch 900/1000 [|TEST DATA|]
		training set loss: nan -- epoch 1000/1000
		testing set loss: nan -- epoch 1000/1000 [|TEST DATA|]
		
	batchSize, dimIn, dimHidden, dimOut, hiddenLayers = 1, 12, 64, 12, 6
	trainSize, testSize = 800, 200
	learningRate, weightDecay = 0.01, 0.001
	numEpochs=1000
	testEvery=50
	Adam
		training set loss: 2.2255942821502686 -- epoch 100/1000
		testing set loss: 2.2216055393218994 -- epoch 100/1000 [|TEST DATA|]
		training set loss: 2.225533962249756 -- epoch 200/1000
		testing set loss: 2.2211577892303467 -- epoch 200/1000 [|TEST DATA|]
		training set loss: nan -- epoch 300/1000
		testing set loss: nan -- epoch 300/1000 [|TEST DATA|]
		training set loss: nan -- epoch 400/1000
		testing set loss: nan -- epoch 400/1000 [|TEST DATA|]
		training set loss: nan -- epoch 500/1000
		testing set loss: nan -- epoch 500/1000 [|TEST DATA|]
		training set loss: nan -- epoch 600/1000
		testing set loss: nan -- epoch 600/1000 [|TEST DATA|]
		training set loss: nan -- epoch 700/1000
		testing set loss: nan -- epoch 700/1000 [|TEST DATA|]
		training set loss: nan -- epoch 800/1000
		testing set loss: nan -- epoch 800/1000 [|TEST DATA|]
		training set loss: nan -- epoch 900/1000
		testing set loss: nan -- epoch 900/1000 [|TEST DATA|]
		training set loss: nan -- epoch 1000/1000
		testing set loss: nan -- epoch 1000/1000 [|TEST DATA|]

NEW STRUCTURE:
now showing error as the index where the target note appears in the distribution output sorted by size
Sequences now have variable length, which can be tuned as a hyperparameter
Added weight reduction hyperparameters for the repeat note and fith interval note in the NLLLoss function
	
	Input dimension = 12, Hidden dimension =64, Output dimension = 12, Hidden layers = 4
	Train set size = 800, Test set size = 100
	Learning Rate = 0.001, Weight decay = 0.001
	Repeat note weight = 0.5, Fith note weight = 0.5
	Sequence length = 8
	Epochs = 10
	Optimisation algorithm = SGD
		testing set loss: 4.295999582545969 -- epoch 0/10 [|TEST DATA|]
		training set loss: 3.442962819179802 -- epoch 2/10
		testing set loss: 3.549028870237678 -- epoch 2/10 [|TEST DATA|]
		training set loss: 3.4455643204564375 -- epoch 4/10
		testing set loss: 3.549028870237678 -- epoch 4/10 [|TEST DATA|]
		training set loss: 3.446652017110861 -- epoch 6/10
		testing set loss: 3.549028870237678 -- epoch 6/10 [|TEST DATA|]
		training set loss: 3.4473132191297684 -- epoch 8/10
		testing set loss: 3.549028870237678 -- epoch 8/10 [|TEST DATA|]
		training set loss: 3.447744740447353 -- epoch 10/10
		testing set loss: 3.549028870237678 -- epoch 10/10 [|TEST DATA|]

	Input dimension = 12, Hidden dimension =64, Output dimension = 12, Hidden layers = 4
	Train set size = 800, Test set size = 100
	Learning Rate = 0.01, Weight decay = 0.001
	Repeat note weight = 0.5, Fith note weight = 0.5
	Sequence length = 8
	Epochs = 10
	Optimisation algorithm = SGD
		testing set loss: 5.70447610641781 -- epoch 0/10 [|TEST DATA|]
		training set loss: 3.233241370924025 -- epoch 2/10
		testing set loss: 3.5729762955493234 -- epoch 2/10 [|TEST DATA|]
		training set loss: 3.2343395996976008 -- epoch 4/10
		testing set loss: 3.5729762955493234 -- epoch 4/10 [|TEST DATA|]
		training set loss: 3.234381780802745 -- epoch 6/10
		testing set loss: 3.5729762955493234 -- epoch 6/10 [|TEST DATA|]
		training set loss: 3.234401541320473 -- epoch 8/10
		testing set loss: 3.5729762955493234 -- epoch 8/10 [|TEST DATA|]
		training set loss: 3.2344140816490388 -- epoch 10/10
		testing set loss: 3.5729762955493234 -- epoch 10/10 [|TEST DATA|]
		
	Input dimension = 12, Hidden dimension =64, Output dimension = 12, Hidden layers = 4
	Train set size = 800, Test set size = 100
	Learning Rate = 0.0001, Weight decay = 0.001
	Repeat note weight = 0.5, Fith note weight = 0.5
	Sequence length = 8
	Epochs = 10
	Optimisation algorithm = SGD
		testing set loss: 5.630050259282127 -- epoch 0/10 [|TEST DATA|]
		training set loss: 3.480664496793466 -- epoch 2/10
		testing set loss: 3.499311243206138 -- epoch 2/10 [|TEST DATA|]
		training set loss: 3.480783575197329 -- epoch 4/10
		testing set loss: 3.499311243206138 -- epoch 4/10 [|TEST DATA|]
		training set loss: 3.481286219681039 -- epoch 6/10
		testing set loss: 3.499311243206138 -- epoch 6/10 [|TEST DATA|]
		training set loss: 3.4814155160337807 -- epoch 8/10
		testing set loss: 3.4991190900425813 -- epoch 8/10 [|TEST DATA|]
		training set loss: 3.4817440623890965 -- epoch 10/10
		testing set loss: 3.498946900844073 -- epoch 10/10 [|TEST DATA

	Input dimension = 12, Hidden dimension =64, Output dimension = 12, Hidden layers = 4
	Train set size = 800, Test set size = 100
	Learning Rate = 0.001, Weight decay = 0.005
	Repeat note weight = 0.5, Fith note weight = 0.5
	Sequence length = 8
	Epochs = 10
	Optimisation algorithm = SGD
		testing set loss: 6.365745407353153 -- epoch 0/10 [|TEST DATA|]
		training set loss: 3.4611320242146753 -- epoch 2/10
		testing set loss: 3.6618986719753206 -- epoch 2/10 [|TEST DATA|]
		training set loss: 3.4630477798068684 -- epoch 4/10
		testing set loss: 3.6618986719753206 -- epoch 4/10 [|TEST DATA|]
		training set loss: 3.4635743168945314 -- epoch 6/10
		testing set loss: 3.6618986719753206 -- epoch 6/10 [|TEST DATA|]
		training set loss: 3.463739527444512 -- epoch 8/10
		testing set loss: 3.6618986719753206 -- epoch 8/10 [|TEST DATA|]
		training set loss: 3.4638414009245193 -- epoch 10/10
		testing set loss: 3.6618986719753206 -- epoch 10/10 [|TEST DATA|]

	Input dimension = 12, Hidden dimension =64, Output dimension = 12, Hidden layers = 4
	Train set size = 800, Test set size = 100
	Learning Rate = 0.01, Weight decay = 0.005
	Repeat note weight = 0.5, Fith note weight = 0.5
	Sequence length = 8
	Epochs = 10
	Optimisation algorithm = SGD
		testing set loss: 5.297820540936408 -- epoch 0/10 [|TEST DATA|]
		training set loss: 3.1993064767712247 -- epoch 2/10
		testing set loss: 3.475783325514178 -- epoch 2/10 [|TEST DATA|]
		training set loss: 3.198987171579314 -- epoch 4/10
		testing set loss: 3.475783325514178 -- epoch 4/10 [|TEST DATA|]
		training set loss: 3.198845300649741 -- epoch 6/10
		testing set loss: 3.475783325514178 -- epoch 6/10 [|TEST DATA|]
		training set loss: 3.198787940435627 -- epoch 8/10
		testing set loss: 3.475783325514178 -- epoch 8/10 [|TEST DATA|]
		training set loss: 3.1987596427300002 -- epoch 10/10
		testing set loss: 3.475783325514178 -- epoch 10/10 [|TEST DATA|]

	Input dimension = 12, Hidden dimension =64, Output dimension = 12, Hidden layers = 4
	Train set size = 800, Test set size = 100
	Learning Rate = 0.0001, Weight decay = 0.005
	Repeat note weight = 0.5, Fith note weight = 0.5
	Sequence length = 8
	Epochs = 10
	Optimisation algorithm = SGD
		testing set loss: 5.89464820001163 -- epoch 0/10 [|TEST DATA|]
		training set loss: 3.507517957246949 -- epoch 2/10
		testing set loss: 3.5247111661167736 -- epoch 2/10 [|TEST DATA|]
		training set loss: 3.507850901120589 -- epoch 4/10
		testing set loss: 3.5247111661167736 -- epoch 4/10 [|TEST DATA|]
		training set loss: 3.508246896720794 -- epoch 6/10
		testing set loss: 3.5247111661167736 -- epoch 6/10 [|TEST DATA|]
		training set loss: 3.5082522791852764 -- epoch 8/10
		testing set loss: 3.5247111661167736 -- epoch 8/10 [|TEST DATA|]
		training set loss: 3.5083514703162026 -- epoch 10/10
		testing set loss: 3.5247111661167736 -- epoch 10/10 [|TEST DATA|]	
	

		